{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5676d2f",
   "metadata": {},
   "source": [
    "# Signal preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90407e",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwpy.timeseries import TimeSeries # time domain data array in gwpy\n",
    "from gwpy.plot import Plot # plotting in gwpy\n",
    "from scipy.signal import hann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbef23",
   "metadata": {},
   "source": [
    "#### Q-Transform\n",
    "The constant quality factor transform (CQT), introduced by J.C. Brown in 1988, is an interesting alternative to the windowed Fourier transform (STFT / Short Time Fourier Transform) or wavelets, for time-frequency analysis.\n",
    "\n",
    "The constant-Q transform transforms a data series to the frequency domain. It is related to the Fourier transform. In general, the transform is well suited to musical data and proves useful where frequencies span several octaves.It is more useful in the identification of instruments.\n",
    "\n",
    "Unlike the Fourier transform, but similar to the mel scale, the constant-Q transform (Wikipedia) uses a logarithmically spaced frequency axis. The original paper reference below\n",
    "\n",
    "Judith C. Brown, \"Calculation of a constant Q spectral transform,\" J. Acoust. Soc. Am., 89(1):425â€“434, 1991.\n",
    "\n",
    "From Wikipedia - In mathematics and signal processing, the constant-Q transform, simply known as CQT transforms a data series to the frequency domain. It is related to the Fourier transform[1] and very closely related to the complex Morlet wavelet transform. In general, the transform is well suited to musical data, and this can be seen in some of its advantages compared to the fast Fourier transform. As the output of the transform is effectively amplitude/phase against log frequency, fewer frequency bins are required to cover a given range effectively, and this proves useful where frequencies span several octaves. As the range of human hearing covers approximately ten octaves from 20 Hz to around 20 kHz, this reduction in output data is significant.\n",
    "\n",
    "A Constant Q transform is a variation on the Discrete Fourier Transform (DFT). In other words, it is a type of wavelet transform.\n",
    "\n",
    "I only have a casual understanding of both types of transforms myself, so take what I'm saying with a grain of salt.\n",
    "\n",
    "A standard DFT uses a constant window size throughout all frequencies. This typically leads to a pretty consistent, fully continuous transform. However, the constant bin size for all frequencies leads to some problems when you map frequency on a logarithmic scale. Specifically, peaks on the lower end are incredibly wide (sometimes up to half an octave), lacking any sort of detail.\n",
    "\n",
    "This is an issue for emulating human perception because humans perceive frequency on a logarithmic scale.\n",
    "\n",
    "A Constant Q transform seeks to solve this problem by increasing the window size for lower frequencies, and alleviate some of the computational strain caused by this by reducing the window size used for high frequencies. It's pretty effective at this, but has a few drawbacks.\n",
    "\n",
    "The computational complexity of a Constant Q transform is only slightly larger than that of a standard DFT, but because the window size changes per frequency, it is impossible to apply the typical optimizations of the FFT to a Constant Q transform.\n",
    "\n",
    "In other words, a Constant Q transform will yield better results where low frequencies and logarithmic frequency mapping are concerned.\n",
    "\n",
    "The transform exhibits a reduction in frequency resolution with higher frequency bins, which is desirable for auditory applications. The transform mirrors the human auditory system, whereby at lower-frequencies spectral resolution is better, whereas temporal resolution improves at higher frequencies.\n",
    "\n",
    "CQT refers to a time-frequency representation where the frequency bins are geometrically spaced and the Q-factors (ratios of the center frequencies to bandwidths) of all bins are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee00c27",
   "metadata": {},
   "source": [
    "## Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/data_path.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f841e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = glob(\"D:/Projects/G2Net-Gravitational-Wave-Detection/data/train/*/*/*/*\")\n",
    "print(\"The total number of files in the training set:\", len(training_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [path.split(\"\\\\\")[-1].split(\".\")[0] for path in training_paths]\n",
    "paths_df = pd.DataFrame({\"path\":training_paths, \"id\": ids})\n",
    "train_data = pd.merge(left=training_labels, right=paths_df, on=\"id\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6172eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 2048\n",
    "signal_length = 2\n",
    "NFFT = 4*sample_rate    # the Nyquist frequency -\n",
    "f_min = 20.\n",
    "f_max = sample_rate/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cdef6",
   "metadata": {},
   "source": [
    "## Signal preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4635d",
   "metadata": {},
   "source": [
    "##### Typical signal processing workflow\n",
    "Next, we try to implement the steps from this paper referenced above by following these steps:\n",
    "\n",
    "- Plot the raw signal\n",
    "- Window the signal\n",
    "- Whiten the signal\n",
    "- Bandpass the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_data(path,\n",
    "           df,\n",
    "           target,\n",
    "           labels = ('LIGO Hanford', 'LIGO Livingston', 'Virgo')\n",
    "):\n",
    "    sample_id = df[df['target'] == target].sample(random_state=42)['id'].values[0]\n",
    "    sample_id = int(sample_id)\n",
    "    training_files = glob(path)\n",
    "    data = np.load(training_files[sample_id])\n",
    "    fig, ax = plt.subplots(1,1,figsize=(12,10), sharey= True) \n",
    " \n",
    "    plt.suptitle(f\"Strain data for LIGO Hanford observatory from sample: {sample_id} | Target: {target}\")\n",
    "    sns.lineplot(data=data[0], ax=ax, color=sns.color_palette()[i])\n",
    "    ax.legend([labels[i]])\n",
    "    ax.set_xlim(0, 4096)\n",
    "    ax.set_xticks(ticks=[0, 2048, 4096])\n",
    "    ax.set_xticklabels(labels=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_raw_data(training_paths,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw signal\n",
    "sample_gw_ts = TimeSeries(training_paths[0], sample_rate=sample_rate)\n",
    "plot = sample_gw_ts.Plot()\n",
    "ax = plot.gca()\n",
    "ax.set_xlim(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a window of lenght of the signal\n",
    "hann_win = hann(sample_rate*signal_length, False)\n",
    "plt.plot(hann_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the windowed signal\n",
    "sample_gw_ts_win = sample_gw_ts * hann_win\n",
    "plot = sample_gw_ts_win.Plot()\n",
    "ax = plot.gca()\n",
    "ax.set_xlim(0, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45236e2",
   "metadata": {},
   "source": [
    "This is the windowed signal. Next, let's plot a whitened signal. As mentioned in the tutorial we referenced earlier, whitening the data is suppressing the extra noise at low frequencies and at the spectral lines, to better see the weak signals in the most sensitive band. Whitening is always one of the first steps in astrophysical data analysis (searches, parameter estimation). Whitening requires no prior knowledge of spectral lines, etc; only the data are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the whitened signal\n",
    "plot = sample_gw_ts.whiten().Plot()\n",
    "ax = plot.gca()\n",
    "ax.set_xlim(0, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48437f4a",
   "metadata": {},
   "source": [
    "This is the whitened signal. Next, since we know this data is from merger binary black holes, the frequency is in lower range and this we apply a bandpass filter to passthrough signals between 35 ~ 350 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass the above whitened data and plot\n",
    "plot = sample_gw_ts.whiten().bandpass(35, 350).Plot()\n",
    "ax = plot.gca()\n",
    "ax.set_xlim(0, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a51672",
   "metadata": {},
   "source": [
    "### Signal Transformations - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_mfcc(path,\n",
    "                          df,\n",
    "                          target,\n",
    "                          sr=2048,\n",
    "                          signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n",
    "):\n",
    "    \n",
    "    sample_id = df[df['target'] == target].sample(random_state=42)['id'].values[0]\n",
    "    sample_id = int(sample_id)\n",
    "    training_files = glob(path)\n",
    "    sample = np.load(training_files[sample_id])\n",
    "    \n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i in range(3):\n",
    "        mfccs = librosa.feature.mfcc(sample[i] / sample[i].max(), sr=sr)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        librosa.display.specshow(mfccs, sr=sr, x_axis=\"time\", vmin=-200, vmax=50, cmap=\"coolwarm\")\n",
    "        plt.title(signal_names[i], fontsize=14)\n",
    "        plt.colorbar()\n",
    "\n",
    "    plt.suptitle(f\"Mel Frequency Cepstral Coefficients plots for sample: {sample_id}\", fontsize=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sample wit gravitational wave signal\n",
    "visualize_sample_mfcc(training_paths,train_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d023e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sample without gravitational wave signal\n",
    "visualize_sample_mfcc(training_paths,train_data,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14962c9e",
   "metadata": {},
   "source": [
    "### Signal Transformations - Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f37d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_spectogram(path,\n",
    "    df, \n",
    "    target,\n",
    "    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n",
    "):\n",
    "\n",
    "    # Get the data\n",
    "    sample_id = df[df['target'] == target].sample(random_state=42)['id'].values[0]\n",
    "    sample_id = int(sample_id)\n",
    "    training_files = glob(path)\n",
    "    sample = np.load(training_files[sample_id])\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    \n",
    "    for i in range(3):\n",
    "        X = librosa.stft(sample[i] / sample[i].max())\n",
    "        Xdb = librosa.amplitude_to_db(abs(sample))\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        librosa.display.specshow(Xdb, sr=2048, x_axis=\"time\", y_axis=\"hz\", vmin=-30, vmax=50) \n",
    "        plt.colorbar()\n",
    "        plt.title(signal_names[i], fontsize=14)\n",
    "\n",
    "    plt.suptitle(f\"Spectrogram plots for sample: {sample_id}\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5312b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sample wit gravitational wave signal\n",
    "visualize_sample_spectogram(training_paths,train_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4831762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sample without gravitational wave signal\n",
    "visualize_sample_spectogram(training_paths,train_data,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bddc74",
   "metadata": {},
   "source": [
    "As seen in the image below, from the publication, our end signal looks very different to one the from the paper. \n",
    "\n",
    "To this end, let's see if we can get any info from the spectrogram images by tranforming the data using Constant Q-Transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f95d1",
   "metadata": {},
   "source": [
    "### Signal Transformations - CQT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae593975",
   "metadata": {},
   "source": [
    "The signal analysis didn't provide much insights, so let's try the second method in signal processing. Tranforming the waves into spectrograms images, i.e. frequency-domain, and then visualize them. This technique is widely used in audio analysis (as shown here on this TensorFlow tutorial) and since our data is a wave with bunch of frequencies, we can use the same technique as well.\n",
    "\n",
    "The advantage of using a spectrogram, over a direct Fourier Transform where you lose time info, is that it captures the shift or change in frequencies over time and this removes white noise frequencies that are persistent, leaving the signals of interest. Constant Q-Transform is one way to visualize the spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the Q-transform spectrogram side-by-side\n",
    "def plot_q_transform_sbs(path,\n",
    "                         df,\n",
    "                         sample_rate,\n",
    "                         signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n",
    "                        ):\n",
    "    # Get the data\n",
    "    sample_1 = df[df['target'] == 1].sample(random_state=42)['id'].values[0]\n",
    "    sample_1 = int(sample_1)\n",
    "    sample_0 = df[df['target'] == 0].sample(random_state=42)['id'].values[0]\n",
    "    sample_0 = int(sample_0)\n",
    "    training_files = glob(path)\n",
    "    sample_1 = np.load(training_files[sample_1])\n",
    "    sample_0 = np.load(training_files[sample_0])\n",
    "    \n",
    "    for i in range(len(signal_names)):\n",
    "        # get the timeseries\n",
    "        ts_gw = TimeSeries(sample_1[i], sample_rate=sample_rate)\n",
    "        ts_no_gw = TimeSeries(sample_0[i], sample_rate=sample_rate)\n",
    "        \n",
    "        # get the Q-transform\n",
    "        image_gw = ts_gw.q_transform(whiten=True)\n",
    "        image_no_gw = ts_no_gw.q_transform(whiten=True)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(image_gw)\n",
    "        plt.title(f\"id: {sample_1} | Target=1\")\n",
    "        plt.grid(False)\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(image_no_gw)\n",
    "        plt.title(f\"id: {sample_0} | Target=0\")\n",
    "        plt.grid(False)\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot two spectrograms for sample w/ and w/o GW signal side-by-side\n",
    "plot_q_transform_sbs(training_paths,train_data,sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c29f5",
   "metadata": {},
   "source": [
    "Visibly, all three signals have different features and the above were plotted from a sample which has gravitational waves, and it shows the famous 'chirp' confirming the presence of gravitational waves. This transformation removes the unwanted noise frequencies, but still some of it remains, but a signal has to be detected in all three waves to be predicted as gravitational wave.\n",
    "\n",
    "Next, we can compare how the Q-Transforms look for samples with and without gravitational wave signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f77f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the Q-transform spectrogram\n",
    "def plot_q_transform(path,\n",
    "                     _id,\n",
    "                     df\n",
    "                    ):\n",
    "    # Get the data\n",
    "    sample_id = df[df['id'] == _id].sample(random_state=42)['id'].values[0]\n",
    "    sample_id = int(sample_id)\n",
    "    training_files = glob(path)\n",
    "    sample = np.load(training_files[sample_id])\n",
    "    \n",
    "    # we convert the data to gwpy's TimeSeries for analysis\n",
    "    for i in range(sample.shape[0]):\n",
    "        ts = TimeSeries(sample[i], sample_rate=sample_rate)\n",
    "        ax = ts.q_transform(whiten=True).plot().gca()\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_title(f\"Spectrogram plots for sample: {sample_id} from {obs_list[i]}\")\n",
    "        ax.grid(False)\n",
    "        \n",
    "        ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the sample with obvious \"chirp\"\n",
    "# id from: https://www.kaggle.com/mistag/data-preprocessing-with-gwpy\n",
    "plot_q_transform(training_paths,'0021f9dd71',train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb69a6",
   "metadata": {},
   "source": [
    "This clearly visible \"chirp\" can be seen with minimal background noise and is one of the good samples where the signal-to-ratio is quite strong, but as mentioned not all samples are like this and thus we use ML models to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = sample_gw_ts_win.asd(fftlength=2).plot(figsize=[12, 6])\n",
    "plt.xlim(10,1024)\n",
    "plt.ylim(1e-25, 1e-20);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
