{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb99bcbc",
   "metadata": {},
   "source": [
    "# Teoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f22490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Awantikashri/Gravitational-Wave-Detection-Using-Deep-Learning/blob/main/g2net-eda-preprocessing-model.ipynb\n",
    "# Como el mio pero con cositas, mirarlo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065a43c",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd46bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/YuriMiyamori/g2net-gravitational-wave-detection/blob/main/notebooks/00_EDA.ipynb\n",
    "\n",
    "using DataFrames, DataFramesMeta, CSV\n",
    "using NPZ\n",
    "using Random, Statistics\n",
    "using DSP,FFTW, AbstractFFTs,Interpolations\n",
    "using Wavelets\n",
    "using ContinuousWavelets\n",
    "\n",
    "using PyPlot\n",
    "plt.style.use(\"seaborn-whitegrid\");\n",
    "rcParams = PyPlot.PyDict(PyPlot.matplotlib.\"rcParams\")\n",
    "rcParams[\"font.size\"] = 12\n",
    "rcParams[\"figure.figsize\"] = [16,16]\n",
    "rcParams[\"figure.dpi\"] = 220;\n",
    "\n",
    "\n",
    "\n",
    "h = data[:, 1]\n",
    "h_in_sig = data_in_sig[:, 1]\n",
    "h̃ = dt * FFTW.rfft(h) \n",
    "h̃_in_sig = dt * FFTW.rfft(h_in_sig) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function noise_detect(h, h̃, tnumber_of_chunks, overlap_rate)\n",
    "    t = (1:length(h)) .*dt  |> collect\n",
    "    frequencies = FFTW.rfftfreq(length(h), sampling_rate)\n",
    "    # frequencies = FFTW.rfftfreq(length(h), sampling_rate)\n",
    "    points_per_chunk = 2^floor(Int, log2(length(h)/number_of_chunks))\n",
    "\n",
    "    s = welch_pgram(h, points_per_chunk, floor(Int, points_per_chunk*overlap_rate), fs=sampling_rate, window=hanning)\n",
    "    f_noise, noise_welch = s.freq, s.power\n",
    "\n",
    "    noise_spectral_density = sqrt.(2 * length(h) .* noise_welch ./ sampling_rate)\n",
    "    nodes = (f_noise,)\n",
    "    itp = interpolate(nodes, noise_spectral_density, Gridded(Linear()))\n",
    "    noise_spectral_density_interpolator = itp(frequencies);\n",
    "    @show(size(noise_spectral_density_interpolator))\n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    ax.loglog(frequencies, abs.(h̃), label=\"Raw data\", alpha=0.3)\n",
    "    ax.loglog(f_noise, noise_spectral_density, label=\"Noise estimate\")\n",
    "    ax.set_xlim(8, 0.6*sampling_rate)\n",
    "    ax.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax.set_ylabel(\"Noise spectrum and strain Fourier transform (seconds)\")\n",
    "    ax.legend();\n",
    "    # @show(htilde ./ noise_spectral_density_interpolator)\n",
    "\n",
    "    h̃_equalized = h̃ ./ noise_spectral_density_interpolator\n",
    "    #h_equalized = fade(sampling_rate * FFTW.irfft(htilde_equalized, length(t)));\n",
    "    h_equalized = (sampling_rate * FFTW.irfft(h̃_equalized, length(t)));\n",
    "    score = mean(abs.(h_equalized))\n",
    "    ax.set_title(\"number_of_chunks:: $number_of_chunks, overlap_rate:: $overlap_rate => score:: $score\")\n",
    "\n",
    "    # Now we transform back to the time domain, and smoothly fade on and off to get rid of loud clicks\n",
    "    plot_td_and_fd(h_equalized,  h̃ ./ h̃[length(h̃) - div(length(h̃), 4)]/10, h̃_equalized)\n",
    "    return h_equalized, h̃_equalized\n",
    "end\n",
    "\n",
    "number_of_chunks = 16\n",
    "h_equalized, h̃_equalized= noise_detect(h, h̃, number_of_chunks, 0.5)\n",
    "h_equalized_in_sig, h̃_equalized_in_sig= noise_detect(h_in_sig, h̃_in_sig, number_of_chunks, 0.5)\n",
    "\n",
    "\"\"\"\n",
    "for number_of_chunks in 2:8\n",
    "    noise_detect(number_of_chunks, 0.8)\n",
    "end\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b661e6",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/YuriMiyamori/g2net-gravitational-wave-detection/blob/main/notebooks/LOSC_Event_tutorial.ipynb\n",
    "def whiten(strain, interp_psd, dt):\n",
    "    Nt = len(strain)\n",
    "    freqs = np.fft.rfftfreq(Nt, dt)\n",
    "    freqs1 = np.linspace(0,2048.,Nt/2+1)\n",
    "\n",
    "    # whitening: transform to freq domain, divide by asd, then transform back, \n",
    "    # taking care to get normalization right.\n",
    "    hf = np.fft.rfft(strain)\n",
    "    norm = 1./np.sqrt(1./(dt*2))\n",
    "    white_hf = hf / np.sqrt(interp_psd(freqs)) * norm\n",
    "    white_ht = np.fft.irfft(white_hf, n=Nt)\n",
    "    return white_ht\n",
    "\n",
    "# make wav (sound) files from the whitened data, +-2s around the event.\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# function to keep the data within integer limits, and write to wavfile:\n",
    "def write_wavfile(filename,fs,data):\n",
    "    d = np.int16(data/np.max(np.abs(data)) * 32767 * 0.9)\n",
    "    wavfile.write(filename,int(fs), d)\n",
    "\n",
    "deltat_sound = 2.                     # seconds around the event\n",
    "\n",
    "# index into the strain time series for this time interval:\n",
    "indxd = np.where((time >= tevent-deltat_sound) & (time < tevent+deltat_sound))\n",
    "\n",
    "# write the files:\n",
    "write_wavfile(eventname+\"_H1_whitenbp.wav\",int(fs), strain_H1_whitenbp[indxd])\n",
    "write_wavfile(eventname+\"_L1_whitenbp.wav\",int(fs), strain_L1_whitenbp[indxd])\n",
    "\n",
    "# re-whiten the template using the smoothed PSD; it sounds better!\n",
    "template_p_smooth = whiten(template_p,psd_smooth,dt)\n",
    "\n",
    "# and the template, sooming in on [-3,+1] seconds around the merger:\n",
    "indxt = np.where((time >= (time[0]+template_offset-deltat_sound)) & (time < (time[0]+template_offset+deltat_sound)))\n",
    "write_wavfile(eventname+\"_template_whiten.wav\",int(fs), template_p_smooth[indxt])\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "fna = eventname+\"_template_whiten.wav\"\n",
    "print(fna)\n",
    "Audio(fna)\n",
    "\n",
    "\n",
    "fna = eventname+\"_H1_whitenbp.wav\"\n",
    "print(fna)\n",
    "Audio(fna)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbd85e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/JamesMcGuigan/kaggle-gravitational-waves/blob/master/src/experiments/rnn_starter/model.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    inputs = layers.Input(shape=(27, 128))\n",
    "\n",
    "    gru1  = layers.Bidirectional(layers.GRU(128, return_sequences=True), name='gru_1')\n",
    "    gru2  = layers.Bidirectional(layers.GRU(128, return_sequences=True), name='gru_2')\n",
    "    pool1 = layers.GlobalAveragePooling1D(name='avg_pool')\n",
    "    pool2 = layers.GlobalMaxPooling1D(name='max_pool')\n",
    "\n",
    "    x = gru1(inputs)\n",
    "    x = gru2(x)\n",
    "    x = tf.keras.layers.Concatenate()([pool1(x), pool2(x)])\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1,   activation=\"sigmoid\", name=\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202554b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pranay1990/G2NET_Gravitational_Wave_Detection/blob/main/effnetb6-cwt.ipynb\n",
    "\n",
    "def get_model(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16,input_shape=input_shape, kernel_size=3,))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(32,kernel_size=1,dilation_rate=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(64,kernel_size=1 ,dilation_rate=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer = Adam(lr=1e-3),loss='binary_crossentropy',metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "model = get_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',factor=np.sqrt(0.01), cooldown=0,\\\n",
    "                               patience=3, min_lr=0.5e-8,mode='min')\n",
    "# This file path where the best weights will be saved\n",
    "checkpoint_filepath = '/content/tfm_g2n/model_cnn.h5'\n",
    "# It saves the weights which shows the highest validation accuracy\n",
    "modelchck=ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,verbose=1,\n",
    "                          monitor='val_auc',mode='max',save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset, validation_data=valid_dataset, epochs = 10, bach_size= 250, callbacks=[lr_reducer,modelchck])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
