{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gwpy\n",
        "import gwpy\n",
        "from gwpy.timeseries import TimeSeries"
      ],
      "metadata": {
        "id": "gWYeAMc_2euc"
      },
      "id": "gWYeAMc_2euc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "id": "lPIku7jA2ial"
      },
      "id": "lPIku7jA2ial",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "WYoBx-hI2kkn"
      },
      "id": "WYoBx-hI2kkn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "BKav9m6f2m6E"
      },
      "id": "BKav9m6f2m6E",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "0Ulqj9v62ogu"
      },
      "id": "0Ulqj9v62ogu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "t5tJchW32qP3"
      },
      "id": "t5tJchW32qP3",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "TT8Tr-Xt2rlw"
      },
      "id": "TT8Tr-Xt2rlw",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SpmVHlSy2tGa"
      },
      "id": "SpmVHlSy2tGa",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c g2net-gravitational-wave-detection"
      ],
      "metadata": {
        "id": "Q_7bTd7T2tJT"
      },
      "id": "Q_7bTd7T2tJT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir tfm_g2n"
      ],
      "metadata": {
        "id": "XqTHsd5c2tMG"
      },
      "id": "XqTHsd5c2tMG",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip g2net-gravitational-wave-detection.zip -d tfm_g2n"
      ],
      "metadata": {
        "id": "bV7aego62tOA"
      },
      "id": "bV7aego62tOA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "dvawHHcs2tQD"
      },
      "id": "dvawHHcs2tQD",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gwpy.timeseries import TimeSeries # time domain data array in gwpy\n",
        "from gwpy.plot import Plot # plotting in gwpy\n",
        "from scipy.signal import hann\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.interpolate import interp1d  # interpolating a 1-D function\n",
        "import matplotlib.mlab as mlab  # some MATLAB commands\n",
        "from glob import glob     # pathname management\n",
        "\n",
        "import librosa\n",
        "import librosa.display"
      ],
      "metadata": {
        "id": "Pg8JjbujFt1d"
      },
      "id": "Pg8JjbujFt1d",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = pd.read_csv(\"/content/tfm_g2n/training_labels.csv\")\n",
        "train_labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x5eSWpm32tSe",
        "outputId": "62d714c4-52aa-402b-8010-7a14b0cb860d"
      },
      "id": "x5eSWpm32tSe",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  target\n",
              "0  00000e74ad       1\n",
              "1  00001f4945       0\n",
              "2  0000661522       0\n",
              "3  00007a006a       0\n",
              "4  0000a38978       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40b1278c-4605-410c-9771-32a9d5a7bb98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000e74ad</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001f4945</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000661522</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00007a006a</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000a38978</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40b1278c-4605-410c-9771-32a9d5a7bb98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40b1278c-4605-410c-9771-32a9d5a7bb98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40b1278c-4605-410c-9771-32a9d5a7bb98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_paths = glob(\"/content/tfm_g2n/train/*/*/*/*\")\n",
        "print(\"The total number of files in the training set:\", len(training_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h5Ah5Vu2tUt",
        "outputId": "f334b679-1671-4cad-fa04-f14b6d19484e"
      },
      "id": "_h5Ah5Vu2tUt",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of files in the training set: 560000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [path.split(\"/\")[-1].split(\".\")[0] for path in training_paths]\n",
        "paths_df = pd.DataFrame({\"path\":training_paths, \"id\": ids})\n",
        "train_data = pd.merge(left=train_labels, right=paths_df, on=\"id\")\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1UQonORD2tWq",
        "outputId": "e25d0d8b-28a0-4898-ad93-830568fc73d2"
      },
      "id": "1UQonORD2tWq",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  target                                         path\n",
              "0  00000e74ad       1  /content/tfm_g2n/train/0/0/0/00000e74ad.npy\n",
              "1  00001f4945       0  /content/tfm_g2n/train/0/0/0/00001f4945.npy\n",
              "2  0000661522       0  /content/tfm_g2n/train/0/0/0/0000661522.npy\n",
              "3  00007a006a       0  /content/tfm_g2n/train/0/0/0/00007a006a.npy\n",
              "4  0000a38978       1  /content/tfm_g2n/train/0/0/0/0000a38978.npy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74dda14f-d8d8-454c-9fcc-8cbd91bfc115\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000e74ad</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/tfm_g2n/train/0/0/0/00000e74ad.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001f4945</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/tfm_g2n/train/0/0/0/00001f4945.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000661522</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/tfm_g2n/train/0/0/0/0000661522.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00007a006a</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/tfm_g2n/train/0/0/0/00007a006a.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000a38978</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/tfm_g2n/train/0/0/0/0000a38978.npy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74dda14f-d8d8-454c-9fcc-8cbd91bfc115')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74dda14f-d8d8-454c-9fcc-8cbd91bfc115 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74dda14f-d8d8-454c-9fcc-8cbd91bfc115');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91419897",
      "metadata": {
        "id": "91419897"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d476ec1a",
      "metadata": {
        "id": "d476ec1a"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "10560634",
      "metadata": {
        "id": "10560634"
      },
      "outputs": [],
      "source": [
        "# Import tensorflow and sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPool1D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "# To set learning rate\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9033f27e",
      "metadata": {
        "id": "9033f27e"
      },
      "source": [
        "## Setup variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd402fd8",
      "metadata": {
        "id": "fd402fd8"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"data/data_path.csv\")\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84855949",
      "metadata": {
        "id": "84855949"
      },
      "outputs": [],
      "source": [
        "training_paths = glob(\"D:/Projects/G2Net-Gravitational-Wave-Detection/data/train/*/*/*/*\")\n",
        "print(\"The total number of files in the training set:\", len(training_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3520477",
      "metadata": {
        "id": "a3520477"
      },
      "outputs": [],
      "source": [
        "ids = [path.split(\"\\\\\")[-1].split(\".\")[0] for path in training_paths]\n",
        "paths_df = pd.DataFrame({\"path\":training_paths, \"id\": ids})\n",
        "train_data = pd.merge(left=training_labels, right=paths_df, on=\"id\")\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd201220",
      "metadata": {
        "id": "dd201220"
      },
      "source": [
        "# Modelo de https://github.com/Rtavakol/Kaggle_G2Net-Gravitational-Wave-Detection/blob/main/Gravitational_wave.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bb63a77",
      "metadata": {
        "id": "5bb63a77"
      },
      "outputs": [],
      "source": [
        "# Make a simple sequential model with one conv layers\n",
        "model = Sequential()\n",
        "\n",
        "# step 1: 1st Convlution layer\n",
        "model.add(Conv1D(128, kernel_size = 3,activation='relu', input_shape=(3, 4096)))\n",
        "\n",
        "# step 2: Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# step 3: Full connection \n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "# We have a binary classification, so the number of nodes would be 1\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2e49ce",
      "metadata": {
        "id": "3c2e49ce"
      },
      "outputs": [],
      "source": [
        "# Lets train our model using only 10000 time series, \n",
        "# eventually we need to use a data generator as we run out of memory if we want to \n",
        "# use all training and test datasets.\n",
        "N = 1000\n",
        "train_x  = np.zeros((N, 3, 4096))\n",
        "for i in range(N):\n",
        "    data = np.load(training_paths[i])\n",
        "    mean = np.mean(data, axis=1)\n",
        "    std = np.std(data, axis = 1)\n",
        "    data_m = [(data[i] - mean[i])/std[i] for i in range(3)]\n",
        "    train_x[i,:] = data_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d2af12",
      "metadata": {
        "id": "c6d2af12"
      },
      "outputs": [],
      "source": [
        "np.shape(train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d70b7a1",
      "metadata": {
        "id": "1d70b7a1"
      },
      "outputs": [],
      "source": [
        "train_x[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc0ef4ae",
      "metadata": {
        "id": "cc0ef4ae"
      },
      "outputs": [],
      "source": [
        "train_y = training_labels.iloc[:N, 1].values\n",
        "print(len(train_y))\n",
        "train_y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e417d7b9",
      "metadata": {
        "id": "e417d7b9"
      },
      "outputs": [],
      "source": [
        "train_x_reshaped = train_x.reshape(-1,3, 4096)\n",
        "np.shape(train_x_reshaped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a35fe4",
      "metadata": {
        "id": "16a35fe4"
      },
      "outputs": [],
      "source": [
        "train_y_reshaped = train_y.reshape(-1, 1)\n",
        "train_y_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "357275ac",
      "metadata": {
        "id": "357275ac"
      },
      "outputs": [],
      "source": [
        "# Create Keras Callbacks for learning rate\n",
        "my_callbacks_lr = [LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f65e0c72",
      "metadata": {
        "id": "f65e0c72"
      },
      "outputs": [],
      "source": [
        "# Fitting CNN to training dataset\n",
        "result = model.fit(x = train_x_reshaped,\n",
        "              y = train_y_reshaped,\n",
        "              epochs = 20,\n",
        "              batch_size= 32, \n",
        "              verbose= 1, \n",
        "              callbacks= my_callbacks_lr,\n",
        "              validation_split= 0.2,\n",
        "              shuffle= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b571c4e",
      "metadata": {
        "id": "4b571c4e"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "plt.plot(result.history['accuracy'], label = 'Accuracy')\n",
        "plt.plot(result.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('Accuracy.png', dpi = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "795b273f",
      "metadata": {
        "id": "795b273f"
      },
      "outputs": [],
      "source": [
        "# now lets do some experiment with this limitted 10000 samples\n",
        "# first experiment on number of filters\n",
        "n = 4 # number of try\n",
        "model = [0] * n\n",
        "filter_number = [64*(i + 1) for i in range(4)]\n",
        "for i, f in zip(range(N), filter_number):\n",
        "    # Make a simple sequential model with one conv layers\n",
        "    model[i] = Sequential()\n",
        "\n",
        "    # step 1: 1st Convlution layer\n",
        "    model[i].add(Conv1D(f, kernel_size = 3,activation='relu', input_shape=(3, 4096)))\n",
        "\n",
        "    # step 2: Flattening\n",
        "    model[i].add(Flatten())\n",
        "\n",
        "    # step 3: Full connection \n",
        "    model[i].add(Dense(64, activation='relu'))\n",
        "    # We have a binary classification, so the number of nodes would be 1\n",
        "    model[i].add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model[i].compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # Model summary\n",
        "    model[i].summary()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35daf8ef",
      "metadata": {
        "id": "35daf8ef"
      },
      "outputs": [],
      "source": [
        "result = [0] * N\n",
        "for i in range(4): \n",
        "    # Fitting CNN to training dataset\n",
        "    result[i] = model[i].fit(x = train_x_reshaped,\n",
        "              y = train_y_reshaped,\n",
        "              epochs = 20,\n",
        "              batch_size= 32, \n",
        "              verbose= 1, \n",
        "              callbacks= my_callbacks_lr,\n",
        "              validation_split= 0.2,\n",
        "              shuffle= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f77cd07a",
      "metadata": {
        "id": "f77cd07a"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "for i in range(n):\n",
        "    plt.plot(result[i].history['accuracy'], label = 'Model: {}, acc'.format(i))\n",
        "    plt.plot(result[i].history['val_accuracy'], label = 'Model: {}, val_acc'.format(i))\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('models_Accuracy.png', dpi = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "303bbb9f",
      "metadata": {
        "id": "303bbb9f"
      },
      "outputs": [],
      "source": [
        "# We see overfitting for 128 and 256\n",
        "# Let go with 64 filters and now do ecperiment on dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9804768",
      "metadata": {
        "id": "b9804768"
      },
      "outputs": [],
      "source": [
        "model_keras_seq = Sequential()\n",
        "model_keras_seq.add(Conv1D(64, input_shape=(3, 4096), kernel_size=3, activation='relu'))\n",
        "model_keras_seq.add(BatchNormalization())\n",
        "model_keras_seq.add(Flatten())\n",
        "model_keras_seq.add(Dense(64, activation='relu'))\n",
        "model_keras_seq.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_keras_seq.compile(optimizer= Adam(lr=2e-4), loss='binary_crossentropy', metrics=['acc'])\n",
        "model_keras_seq.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76f63046",
      "metadata": {
        "id": "76f63046"
      },
      "outputs": [],
      "source": [
        "# To feed all training data we should define a data generator as the data size is very large and our memory can\n",
        "# not handle it. So, we use a data generator to feed our model batch by batch \n",
        "# in a real time mode instead of a passive mode\n",
        "class data_generator(Sequence):\n",
        "    \n",
        "    def __init__(self, path, list_IDs, data, batch_size):\n",
        "        self.list_IDs = list_IDs\n",
        "        self.data = data\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        \n",
        "    def __len__(self):\n",
        "        len_ = int(len(self.list_IDs)/self.batch_size)\n",
        "        if len_ * self.batch_size < len(self.list_IDs):\n",
        "            len_ += 1\n",
        "        return len_\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        return X, y\n",
        "    \n",
        "    def _data_generator__data_generation(self, list_IDs_temp):\n",
        "        X = np.zeros((self.batch_size, 3, 4096))\n",
        "        y = np.zeros((self.batch_size, 1))\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            id_ = self.data.loc[ID, 'id']\n",
        "            file = id_ + '.npy'\n",
        "            path_in = '/'.join([self.path, id_[0], id_[1], id_[2]]) + '/'\n",
        "            data_array = np.load(path_in + file)\n",
        "            data_array = (data_array - data_array.mean())/data_array.std()\n",
        "            X[i, ] = data_array\n",
        "            y[i, ] = self.data.loc[ID, 'target']\n",
        "        return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24366998",
      "metadata": {
        "id": "24366998"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "sample_submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8a2ba1",
      "metadata": {
        "id": "6f8a2ba1"
      },
      "outputs": [],
      "source": [
        "test_ids = sample_submission['id'].values\n",
        "test_indices = list(sample_submission.index)\n",
        "\n",
        "train_ids = training_labels['id'].values\n",
        "train_y = training_labels.iloc[:, 1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06de2e99",
      "metadata": {
        "id": "06de2e99"
      },
      "outputs": [],
      "source": [
        "train_indices, validation_indices = train_test_split(list(training_labels.index), test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e5491f",
      "metadata": {
        "id": "d5e5491f"
      },
      "outputs": [],
      "source": [
        "root_dir = '../Gravitational_Wave_data/train_extracted/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa58245",
      "metadata": {
        "id": "eaa58245"
      },
      "outputs": [],
      "source": [
        "train_generator = data_generator(root_dir, train_indices, training_labels, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b046a2ef",
      "metadata": {
        "id": "b046a2ef"
      },
      "outputs": [],
      "source": [
        "test_generator  = data_generator(root_dir, test_indices, training_labels, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce58060",
      "metadata": {
        "id": "3ce58060"
      },
      "outputs": [],
      "source": [
        "validation_generator = data_generator(root_dir, validation_indices, sample_submission, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a87592ae",
      "metadata": {
        "id": "a87592ae"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit_generator(generator=train_generator, validation_data=validation_generator, epochs=1, workers=-1)\n",
        "test_prediction = model.predict_generator(test_generator, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9746862",
      "metadata": {
        "id": "e9746862"
      },
      "outputs": [],
      "source": [
        "train_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13380470",
      "metadata": {
        "id": "13380470"
      },
      "outputs": [],
      "source": [
        "training_files[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b72501b",
      "metadata": {
        "id": "2b72501b"
      },
      "outputs": [],
      "source": [
        "train_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b889db04",
      "metadata": {
        "id": "b889db04"
      },
      "outputs": [],
      "source": [
        "sample_submission['target'] = test_prediction[:len(sample_submission)]\n",
        "sample_submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d006ea32",
      "metadata": {
        "id": "d006ea32"
      },
      "source": [
        "# Modelo de https://github.com/rohan-paul/Gravitational-Wave-Detection_Kaggle_Competition/blob/main/Kaggle_NBs/1_TimeSeries_GWPy_Data_Preprocessing.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf6a1745",
      "metadata": {
        "id": "bf6a1745"
      },
      "outputs": [],
      "source": [
        "# ********** FOR GOOGLE DRIVE AND COLAB *****************\n",
        "\n",
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "!python -m pip install gwpy\n",
        "!pip install --upgrade --force-reinstall --no-deps gwpy\n",
        "!pip install astropy\n",
        "!pip install nnAudio\n",
        "!pip install colorama\n",
        "\n",
        "!pip install --upgrade --force-reinstall --no-deps matplotlib\n",
        "\n",
        "!pip install --force-reinstall --no-deps matplotlib==3.2.2\n",
        "# For running in Colab I have to have a previous version of matplotlib\n",
        "# This for Gihut Issue > https://github.com/gwpy/gwpy/issues/1398\n",
        "# More details are in my note in previous cell\n",
        "\n",
        "!pip install gwosc\n",
        "!pip install dqsegdb2\n",
        "!pip install ligotimegps\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "from gwpy.timeseries import TimeSeries\n",
        "from gwpy.plot import Plot\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from colorama import Fore, Back, Style\n",
        "plt.style.use('ggplot')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPool1D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "\n",
        "import torch\n",
        "from nnAudio.Spectrogram import CQT1992v2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1135ffb4",
      "metadata": {
        "id": "1135ffb4"
      },
      "outputs": [],
      "source": [
        "\"\"\" First, we define the constructor to initialize the configuration of the generator.\n",
        "Note that here, we assume the path to the data is in a dataframe column.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "\n",
        "    # For this dataset the list_IDs are the value of the ids\n",
        "    # for each of the time-series file\n",
        "    # i.e. for Train data => values of column 'id' from training_labels.csv\n",
        "\n",
        "    # Also Note we have earlier defined our labels to be the below\n",
        "    # labels = pd.read_csv(root_dir + \"training_labels.csv\")\n",
        "    # and the argument \"data\" is that label here.\n",
        "    def __init__(self, path, list_IDs, data, batch_size):\n",
        "        self.path = path\n",
        "        self.list_IDs = list_IDs\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "\n",
        "    \"\"\" __len__ essentially returns the number of steps in an epoch, using the samples and the batch size.\n",
        "        Each call requests a batch index between 0 and the total number of batches, where the latter is specified in the __len__ method.\n",
        "        A common practice is to set this value to (samples / batch size)\n",
        "        so that the model sees the training samples at most once per epoch.\n",
        "        Now, when the batch corresponding to a given index is called, the generator executes the __getitem__ method to generate it.\n",
        "    \"\"\"\n",
        "\n",
        "    def __len__(self):\n",
        "        len_ = int(len(self.list_IDs)/self.batch_size)\n",
        "        if len_ * self.batch_size < len(self.list_IDs):\n",
        "            len_ += 1\n",
        "        return len_\n",
        "\n",
        "    \"\"\"  __getitem__ method is called with the batch number as an argument to obtain a given batch of data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __getitem__(self, index):\n",
        "        # get the range to to feed to keras for each epoch\n",
        "        # incrementing by +1 the bath_size\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        return X, y\n",
        "\n",
        "    \"\"\" And finally the core method which will actually produce batches of data. This private method __data_generation \"\"\"\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # We have 5,60,000 files, each with dimension of 3 * 4096\n",
        "        X = np.zeros((self.batch_size, 3, 4096))\n",
        "        y = np.zeros((self.batch_size, 1))\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            id_ = self.data.loc[ID, \"id\"]\n",
        "            file = id_ + \".npy\"  # build the file name\n",
        "            path_in = \"/\".join([self.path, id_[0], id_[1], id_[2]]) + \"/\"\n",
        "            # there are three nesting labels inside train/ or test/\n",
        "            data_array = np.load(path_in + file)            \n",
        "            data_array = (data_array - data_array.mean())/data_array.std()\n",
        "            X[i, ] = data_array\n",
        "            y[i, ] = self.data.loc[ID, 'target']\n",
        "        # print(X)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bfa33a7c",
      "metadata": {
        "id": "bfa33a7c"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv('/content/tfm_g2n/sample_submission.csv')\n",
        "# print(len(train_labels)) # 5,60,000\n",
        "# print(len(sample_submission)) # 2,26,000\n",
        "train_ids = train_labels['id'].values\n",
        "# train_ids # ['00000e74ad', '00001f4945', '0000661522' ... ]\n",
        "y = train_labels['target'].values\n",
        "test_ids = sample_submission['id'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d19943e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d19943e0",
        "outputId": "8b1e3e59-79c9-4993-dbbf-b5ff7df46d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184800\n"
          ]
        }
      ],
      "source": [
        "# train_labels = pd.read_csv(root_dir + \"training_labels.csv\", nrows=1000)\n",
        "\n",
        "# ********************\n",
        "\n",
        "# Now I shall genereate train indices, validation indices and test indices\n",
        "# Which are just the values from the 0-based indices\n",
        "train_indices, validation_indices = train_test_split(list(train_labels.index), test_size=0.33, random_state=2021)\n",
        "# print(len(train_indices))\n",
        "print(len(validation_indices))\n",
        "test_indices = list(sample_submission.index)\n",
        "# test_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fafef887",
      "metadata": {
        "id": "fafef887"
      },
      "outputs": [],
      "source": [
        "train_generator_for_seq_model = DataGenerator( '/content/tfm_g2n/train', train_indices, train_labels, 64)\n",
        "# print(train_generator_for_seq_model)\n",
        "\n",
        "validation_generator_for_seq_model = DataGenerator( '/content/tfm_g2n/train', validation_indices, train_labels, 64)\n",
        "test_generator_for_seq_model = DataGenerator( '/content/tfm_g2nd/test', test_indices, sample_submission, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f634a03e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f634a03e",
        "outputId": "f45a662a-d7d1-4a5d-ea56-c8c981c8ed47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 1, 64)             786496    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1, 64)            256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 790,977\n",
            "Trainable params: 790,849\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_keras_seq = Sequential()\n",
        "model_keras_seq.add(Conv1D(64, input_shape=(3, 4096), kernel_size=3, activation='relu'))\n",
        "model_keras_seq.add(BatchNormalization())\n",
        "model_keras_seq.add(Flatten())\n",
        "model_keras_seq.add(Dense(64, activation='relu'))\n",
        "model_keras_seq.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_keras_seq.compile(optimizer= Adam(lr=2e-4), loss='binary_crossentropy', metrics=['acc'])\n",
        "model_keras_seq.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98a0936",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a98a0936",
        "outputId": "151ad1a8-03db-47c4-c3bc-21be19d618bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 362/5863 [>.............................] - ETA: 19:13 - loss: 0.7246 - acc: 0.4904"
          ]
        }
      ],
      "source": [
        "history = model_keras_seq.fit_generator(generator=train_generator_for_seq_model, validation_data=validation_generator_for_seq_model, epochs = 1, workers=-1)\n",
        "# Running for 1 epoch took almost 2 and half hours.\n",
        "\n",
        "predicted_test_seq_keras = model_keras_seq.predict_generator(test_generator_for_seq_model, verbose=1)\n",
        "\n",
        "sample_submission['target'] = predicted_test_seq_keras[:len(sample_submission)]\n",
        "\n",
        "sample_submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8d37e8",
      "metadata": {
        "id": "be8d37e8"
      },
      "source": [
        "# Modelo de https://github.com/PraveenThakkannavar/G2Net-Gravitational-Wave-Detection/blob/main/SIMPLE_CNN.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d59949",
      "metadata": {
        "id": "b0d59949"
      },
      "outputs": [],
      "source": [
        "# Instantiate the Sequential model\n",
        "model_cnn = Sequential(name='CNN_model')\n",
        "\n",
        "# Add the first Convoluted2D layer w/ input_shape & MaxPooling2D layer followed by that\n",
        "model_cnn.add(Conv2D(filters=16,\n",
        "                     kernel_size=3,\n",
        "                     input_shape=input_shape,\n",
        "                     activation='relu',\n",
        "                     name='Conv_01'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=2, name='Pool_01'))\n",
        "\n",
        "# Second pair of Conv1D and MaxPooling1D layers\n",
        "model_cnn.add(Conv2D(filters=32,\n",
        "                     kernel_size=3,\n",
        "                     input_shape=input_shape,\n",
        "                     activation='relu',\n",
        "                     name='Conv_02'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=2, name='Pool_02'))\n",
        "\n",
        "# Third pair of Conv1D and MaxPooling1D layers\n",
        "model_cnn.add(Conv2D(filters=64,\n",
        "                     kernel_size=3,\n",
        "                     input_shape=input_shape,\n",
        "                     activation='relu',\n",
        "                     name='Conv_03'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=2, name='Pool_03'))\n",
        "\n",
        "# Add the Flatten layer\n",
        "model_cnn.add(Flatten(name='Flatten'))\n",
        "\n",
        "# Add the Dense layers\n",
        "model_cnn.add(Dense(units=512,\n",
        "                activation='relu',\n",
        "                name='Dense_01'))\n",
        "model_cnn.add(Dense(units=64,\n",
        "                activation='relu',\n",
        "                name='Dense_02'))\n",
        "\n",
        "# Add the final Output layer\n",
        "model_cnn.add(Dense(1, activation='sigmoid', name='Output'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6475ea77",
      "metadata": {
        "id": "6475ea77"
      },
      "outputs": [],
      "source": [
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3de0418",
      "metadata": {
        "id": "d3de0418"
      },
      "outputs": [],
      "source": [
        "model_cnn.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[[AUC(), 'accuracy']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4a45b2",
      "metadata": {
        "id": "6e4a45b2"
      },
      "outputs": [],
      "source": [
        "# Fit the data\n",
        "history_cnn = model_cnn.fit(x=train_dataset,\n",
        "                            epochs=3,\n",
        "                            validation_data=valid_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            verbose=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "03_Modelling.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}